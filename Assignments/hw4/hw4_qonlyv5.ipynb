{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHPhYAI90KKQ"
   },
   "source": [
    "### 統計學習與深度學習\n",
    "### Homework 4\n",
    "\n",
    "請將IPYNB檔與IPYNB Export之HTML檔上傳至COOL作業區。回答作業時建議使用 \"三明治\" 答題法。也就是說，先說明要做什麼，然後列出程式碼與結果，最後說明這些結果的意義。作業自己做。嚴禁抄襲。不接受紙本繳交，不接受遲交。請以英文或中文作答。\n",
    "\n",
    "#### Multilayer Perceptrons for Regression\n",
    "本次作業的主角是 Multilayer perceptrons (MLP)。我們將以MLP建構迴歸模型，探討各項相關議題。\n",
    "\n",
    "\n",
    "#### Dataset: Million Songs Dataset\n",
    "本次作業將使用\"Million Songs Dataset\"作為訓練與測試資料。請使用`pickle.load()`載入*msd_full.pickle*。這個資料集已經切割好了訓練與測試資料，並存放在一個Dictionary的結構。這個Dictionary有四個元素，x_train, y_train, x_test, y_test，分別對應到訓練特徵、訓練標記(Label)、測試特徵、測試標記。 標記變數 (label variable; i.e., $y$) 是歌曲發行年度。特徵為歌曲的聲音特性。迴歸任務為預測歌曲年分。\n",
    "\n",
    "#### Prediction Performance and Loss Function\n",
    "模型訓練應主要使用Sum of Squared Error (SSE)建構Loss Function，另外我們也會練習使用其他種類的Loss Function。為了讓圖表易於理解，不論Loss Function為何，報告預測能力應使用Root Mean Squared Error (RMSE)。使用SSE或RMSE建構Loss Function在本質上沒有差別。但SSE計算成本稍低，而RMSE較有直觀意義。\n",
    "\n",
    "\n",
    "#### Subtraining, Validation, and Test Datasets\n",
    "*msd_full.pickle* 檔案中的訓練資料已經隨機排序過。你應該使用訓練資料最後10%的資料做為Validation Set。其餘的前90%做為Subtraining Set。使用Subtraining Set來訓練資料，並以Validation Set作為參數調教與Early Stopping的依據。Test RMSE應使用測試資料計算得之。\n",
    "\n",
    "所有特徵應該標準化(均數為零，變異數為一)。標準化應該以訓練資料(注意不是Test Set or Subtraining Set)的統計量為之。標記變數(i.e., $y$)應將均數平移至0 (依照訓練資料的統計量)。標記變數的變異數不要調整。\n",
    "\n",
    "\n",
    "#### Minibatch, Epoch, and Early Stopping\n",
    "如果沒有特別說明，模型訓練時應以大小為1,000個資料點的Minibatch為之。模型使用一個Minibatch的資料更新參數之後稱為經歷了一個Batch。當所有Subtraining資料已經用來更新過模型參數，稱為經過了一個Epoch。\n",
    "\n",
    "模型訓練應使用Early Stopping決定最佳的模型。模型訓練時每100個Batch計算一次Training and Validation RMSE。如果Validation為歷史最低，則記下當下的模型參數與當時已進行的Batch數量，稱為best_step_count。如由best_step_count起算已經經過了5,000個Batch而沒有更好的Validation RMSE，則停止模型訓練，並以best_step_count時的模型參數做為最後的模型訓練結果。如果模型訓練最多執行100個epoch。如果模型已經執行了100個epoch而沒有Early Stop，則應使用歷史最佳的Validation RMSE所對應到的模型參數計算Test RMSE。\n",
    "\n",
    "\n",
    "#### Implementation Restriction\n",
    "使用Pytorch建構MLP模型。Ordinary Least Square (OLS)模型訓練沒有限制使用何種套件。\n",
    "\n",
    "#### 資料載入\n",
    "使用下面的程式碼載入資料:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XR1wx90Fack",
    "outputId": "d28e5023-5120-4f34-9a38-74c6bfd30d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "03Ngn7NMFaVk"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "DATA_PATH = \"/content/drive/My Drive\"\n",
    "infile = open(DATA_PATH+'/msd_full.pickle','rb')\n",
    "msd_data = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDf95kkT0KKV",
    "outputId": "87034d92-182a-47ec-8980-5b4eb1d94be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape =  (463715, 90)\n",
      "Y_train shape =  (463715,)\n",
      "\n",
      "X_subtrain shape =  (417344, 90)\n",
      "Y_subtrain shape =  (417344,)\n",
      "\n",
      "X_valid shape =  (46371, 90)\n",
      "Y_valid shape =  (46371,)\n",
      "\n",
      "X_test shape =  (51630, 90)\n",
      "Y_test shape =  (51630,)\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# # Load data\n",
    "# with open('msd_full.pickle', 'rb') as fh1:\n",
    "#     msd_data = pickle.load(fh1)\n",
    "\n",
    "doscaling = 1\n",
    "if (doscaling == 1):\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    # standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test'].astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_mean = Y_train.mean()\n",
    "Y_train_keep = Y_train.copy()\n",
    "Y_test_keep = Y_test.copy()\n",
    "Y_train = Y_train - y_mean\n",
    "Y_test = Y_test - y_mean\n",
    "\n",
    "\n",
    "# validation is the last 10% of training, subtraining is the first 90% of training\n",
    "nvalid = int(X_train.shape[0] * 0.1)\n",
    "nsubtrain = X_train.shape[0] - nvalid\n",
    "\n",
    "X_subtrain = X_train[0:nsubtrain, :].astype('float32')\n",
    "X_valid = X_train[nsubtrain:, :].astype('float32')\n",
    "Y_subtrain = Y_train[0:nsubtrain].astype('float32')\n",
    "Y_valid = Y_train[nsubtrain:].astype('float32')\n",
    "\n",
    "Y_subtrain_keep = Y_train_keep[0:nsubtrain].astype('float32')\n",
    "Y_valid_keep = Y_train_keep[nsubtrain:].astype('float32')\n",
    "\n",
    "print(\"X_train shape = \", X_train.shape)\n",
    "print(\"Y_train shape = \", Y_train.shape)\n",
    "\n",
    "print(\"\\nX_subtrain shape = \", X_subtrain.shape)\n",
    "print(\"Y_subtrain shape = \", Y_subtrain.shape)\n",
    "\n",
    "print(\"\\nX_valid shape = \", X_valid.shape)\n",
    "print(\"Y_valid shape = \", Y_valid.shape)\n",
    "\n",
    "print(\"\\nX_test shape = \", X_test.shape)\n",
    "print(\"Y_test shape = \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISe-ZaDt0KKW"
   },
   "source": [
    "### 回答下面問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIG21M770KKX"
   },
   "source": [
    "#### Q1 (5%)\n",
    "使用Training資料訓練一個Ordinary Least Square模型，並進行預測。列出此模型的RMSE與前五個特徵的參數。OLS模型應包含常數項，且不應有任何Regularization。\n",
    "\n",
    "#### Q2 MLP with Four Hidden Layers (15%)\n",
    "建構一個有四層Hidden Layer的MLP。此模型由輸入層開始，90個Input Features通過線性層轉換為H個Hidden Nodes，並通過ReLu Activation Function，此為第一層Hidden Layer。\n",
    "接著通過下一個線性層與ReLu Activation Function，此為第二層。接著下一個線性層與ReLu Activation Function，此為第三層。\n",
    "然後下一個線性層與ReLu Activation Function，此為第四層。最後通過一個線性層輸出。\n",
    "所有Hidden Layer的寬度都為H。\n",
    "\n",
    "令H= 45, 使用Stochastic Gradient Descent更新參數，設Learning Rate = 0.00001，無Weight Decay與Momentum。畫出模型訓練過程中的Training與Validation RMSE，列出Test RMSE。 並討論訓練過程中Training與Validation RMSE的圖形意義。\n",
    "\n",
    "#### Q3 (10%)\n",
    "重複上題步驟，使用H = 90與180。無須畫訓練過程的RMSE。列出這兩個Test RMSE。討論H = 45, 90, 180的Test RMSE。\n",
    "\n",
    "#### Q4 (15%)\n",
    "使用Q2的模型設定，考慮 H = 45, 90, 180與Weight Decay = 0.1, 0.2, 0.4的所有組合。模型估計後做表整理Test RMSE。討論H的選擇應為多少較合理?\n",
    "\n",
    "#### Q5 MLP with Dropout (15%)\n",
    "建構一個有Dropout的四層Hidden Layer的MLP。此模型由輸入層開始，第一層由90個Input Features通過線性層轉換為H個Hidden Nodes，通過ReLu Activation Function，之後對Hidden Unit Dropout，機率為0.5。後面各Hidden Lyaer均在ReLu後有Dropout，機率皆為0.5。最後通過一個線性層輸出。所有Hidden Layer的寬度都為H。\n",
    "\n",
    "令H= 90, 使用Adaptive Moment Estimation (Adam)更新參數，設Learning Rate = 0.001，無Weight Decay與Momentum，其他參數使用預設值。畫出模型訓練過程中的Training與Validation RMSE，列出Test RMSE。 並討論訓練過程中Training與Validation RMSE的圖形意義。\n",
    "\n",
    "#### Q6 Explore Number of Hidden Units (10%)\n",
    "使用上題的模型，考慮H = 20, 180, 360。 討論H = 20, 45, 180, 360的Test RMSE。\n",
    "\n",
    "#### Q7 L2 + L1 Loss (15%)\n",
    "我們前面的小題皆是使用SSE，也就是L2 Loss。一個改善模型訓練的方式是使用多種類似的Loss，以線性組合的方式建構Loss Function。請使用Q5中的MLP with Dropout模型 (H = 90)，並以L2 + L1 Loss訓練模型。這個Loss的定義如下:\n",
    "\n",
    "$$\n",
    "loss(\\mathbf{y}, \\hat{\\mathbf{y}}) = z \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + (1 - z) \\sum_{i = 1}^n | y_i - \\hat{y}_i |,\n",
    "$$\n",
    "其中z為實數且$0 <=z <= 1$。\n",
    "\n",
    "使用z = 0.5。並以Adam訓練模型。畫出Training and Validation RMSE，並報告Test RMSE。注意這裡繪圖時應使用RMSE而不是這個特殊的Loss。\n",
    "\n",
    "另外，使用z = 0.0, 0.1, 0.9, 1.0訓練模型(不須提供訓練過程的Loss圖形)，統整各個z值下的Test RMSE並討論。\n",
    "\n",
    "#### Q8 L2 + Customerized Loss (15%)\n",
    "考慮另一個比較特別的Loss Function\n",
    "\n",
    "$$\n",
    "qloss(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\sum_{i=1}^n \\{ q (y_i - \\hat{y}_i)_+ + (1 - q) (\\hat{y}_i - y_i)_+ \\},\n",
    "$$\n",
    "其中q為參數且$0<=q<=1$，而$(y_i - \\hat{y}_i)_+$是取正值的意思。也就是說如果$(y_i - \\hat{y}_i) > 0$，則$(y_i - \\hat{y}_i)_+ = y_i - \\hat{y}_i$，否則$(y_i - \\hat{y}_i)_+ = 0$。\n",
    "\n",
    "令模型的Loss為$z \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + (1 - z) \\sum_{i=1}^n \\{ 0.5 (y_i - \\hat{y}_i)_+ + 0.5 (\\hat{y}_i - y_i)_+ \\} $。請使用Q5中的MLP with Dropout模型(H = 90)，令z = 0。並以Adam訓練模型。畫出Training and Validation RMSE，並報告Test RMSE。注意這裡繪圖時應使用RMSE而不是這個特殊的Loss。\n",
    "\n",
    "另外，使用z = 0.1, 0.5, 0.9, 1.0訓練模型(不須提供訓練過程的Loss圖形)，統整各個z值下的Test RMSE並討論。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl_uRUcQUTef"
   },
   "source": [
    "# A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hPr_AweDF19N"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cl2344Gugx8X"
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "Y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqndQEWYyCDp",
    "outputId": "7acc477e-5ee0-4162-9e75-24fe568358e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.510160684544399"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sk.metrics.mean_squared_error(Y_test, Y_pred))**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8To9f__CbeRU"
   },
   "source": [
    "此模型的RMSE為9.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxE_bmWihlly",
    "outputId": "fe17fd50-c027-441a-f485-ad40b5138451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3097526499730625\n",
      "-2.8808811379532635\n",
      "-1.5323434812890016\n",
      "0.05737582636426097\n",
      "-0.3395288910991756\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  print(reg.coef_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWzb6iKDb4aD"
   },
   "source": [
    "前五項特徵的參數為\n",
    "5.3097526499730625,\n",
    "-2.8808811379532635,\n",
    "-1.5323434812890016,\n",
    "0.05737582636426097,\n",
    "-0.3395288910991756,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy0UUJIwUQ75"
   },
   "source": [
    "# A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7nuyzWHZQs7S"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, Xnp, Ynp):\n",
    "        'Initialization, passing Xnp and Ynp'\n",
    "        self.labels = Ynp\n",
    "        self.nobs = Xnp.shape[0]        \n",
    "        self.Xnp = Xnp\n",
    "        self.Ynp = Ynp\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.nobs\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'        \n",
    "        X = self.Xnp[index]\n",
    "        y = self.Ynp[index]\n",
    "        return X, y\n",
    "    \n",
    "#y_train is a pandas.core.series.Series    \n",
    "trainset = Dataset(X_train, Y_train)\n",
    "subtrainset = Dataset(X_subtrain, Y_subtrain)\n",
    "validset = Dataset(X_valid, Y_valid)\n",
    "testset = Dataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZQX5cLGLQs4U"
   },
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(trainset, batch_size=1000, shuffle=True, num_workers=0)\n",
    "subtrainloader = data.DataLoader(subtrainset, batch_size=1000, shuffle=True, num_workers=0)\n",
    "validloader = data.DataLoader(validset, batch_size=1000, shuffle=True, num_workers=0)\n",
    "testloader = data.DataLoader(testset, batch_size=1000, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OW31XVIiQs2H",
    "outputId": "7fec436f-6e3e-4d71-f998-a5ed1f6f544e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch size: torch.Size([1000, 90])\n",
      "Y_batch size: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "X_batch, Y_batch = next(iter(subtrainloader))\n",
    "print(\"X_batch size:\", X_batch.size())\n",
    "print(\"Y_batch size:\", Y_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDv81ZhmXXGM",
    "outputId": "c747aeef-de88-4928-a5a7-ea51bb3419ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device = \"cuda\"   \n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Running on device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KMjnBXTIQszZ"
   },
   "outputs": [],
   "source": [
    "D_in = trainset.Xnp.shape[1]\n",
    "H = 45\n",
    "\n",
    "D_out = 1\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),  \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, D_out)\n",
    ")\n",
    "# convert everything to float precision. \n",
    "net = net.float()\n",
    "# move the model to device (i.e., cpu or gpu)\n",
    "net = net.to(device)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt-AGwwkQsrS"
   },
   "outputs": [],
   "source": [
    "nepoch = 100\n",
    "step_count = 0\n",
    "log_interval = 100\n",
    "\n",
    "SSE = 0\n",
    "MSE = 0\n",
    "stop_count = 0\n",
    "best_step_count = 0\n",
    "\n",
    "train_RMSE = np.array([])\n",
    "valid_RMSE = np.array([])\n",
    "best_valid_RMSE = 10000\n",
    "\n",
    "weight = []\n",
    "\n",
    "for epoch_id in range(0, nepoch):      \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1        \n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.float())        \n",
    "        loss = loss_fn(outputs.float(), targets.float())\n",
    "\n",
    "        SSE += loss.item()\n",
    "        RMSE = (SSE/(step_count*1000))**(1/2)\n",
    "        train_RMSE = np.append(train_RMSE, RMSE)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(list(net.parameters()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_SSE = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                targets = targets.reshape((-1, 1))\n",
    "                outputs = net(inputs)\n",
    "                cn_loss = loss_fn(outputs, targets)\n",
    "                valid_SSE += cn_loss.item()\n",
    "\n",
    "            valid_tem_rmse = (valid_SSE/46371)**(1/2)\n",
    "            valid_RMSE = np.append(valid_RMSE, valid_tem_rmse)\n",
    "\n",
    "        # if step_count % log_interval == 0:            \n",
    "            # print(\"Epoch %d Step %d Loss = %.3f (minibatch size = %d)\" % (epoch_id, step_count, loss.item(), len(targets)))\n",
    "            # print(RMSE)\n",
    "            # print(valid_tem_rmse)\n",
    "\n",
    "        if valid_tem_rmse < best_valid_RMSE:\n",
    "          best_valid_RMSE = valid_tem_rmse\n",
    "          best_step_count = step_count\n",
    "          stop_count = 0\n",
    "          weight = net.parameters\n",
    "          # print(weight)\n",
    "        else:\n",
    "          stop_count += 1\n",
    "          print(stop_count)\n",
    "\n",
    "        if stop_count == 5000:\n",
    "          break\n",
    "    if stop_count == 5000:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtUq58rWb549",
    "outputId": "cc9d7149-b9f1-4a3c-9c95-8d625287ca21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5072\n"
     ]
    }
   ],
   "source": [
    "print(best_step_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "zpnqa_QBfGd0",
    "outputId": "cfbbe245-dde5-4deb-ea63-b5fd0054907c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(valid_RMSE)), valid_RMSE, label='Validation')\n",
    "plt.plot(range(len(train_RMSE)), train_RMSE, label='Training')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saJrf0BrnQ20"
   },
   "source": [
    "Training RMSE 線條較滑順，且持續在緩緩下降，因為learning rate小再加上套回自己本身的緣故，Training RMSE很少有上升的趨勢；而Validation RMSE則有許多小起伏，也相對Training較早收斂，在第5000個batch就遇到最小的RMSE了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaLWsXT5fGVT",
    "outputId": "d0e18724-f150-4f25-ae66-fee865000b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE(H=45) = 8.867488\n"
     ]
    }
   ],
   "source": [
    "net.apply(weight)\n",
    "\n",
    "with torch.no_grad():\n",
    "  test_SSE = 0\n",
    "  for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    targets = targets.reshape((-1, 1))\n",
    "    outputs = net(inputs)\n",
    "    cn_loss = loss_fn(outputs, targets)\n",
    "    test_SSE += cn_loss.item()\n",
    "\n",
    "  test_rmse = (test_SSE/51630)**(1/2)\n",
    "print(\"Test RMSE(H=45) = %f\" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mwa816nj2bz3"
   },
   "source": [
    "# A3 換成不同H\n",
    "H= 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIbKmuOB2j3n"
   },
   "outputs": [],
   "source": [
    "D_in = trainset.Xnp.shape[1]\n",
    "H = 90\n",
    "D_out = 1\n",
    "\n",
    "net_90 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),  \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, D_out)\n",
    ")\n",
    "# convert everything to float precision. \n",
    "net_90 = net_90.float()\n",
    "# move the model to device (i.e., cpu or gpu)\n",
    "net_90 = net_90.to(device)\n",
    "\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(net_90.parameters(), lr=0.00001)\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "nepoch = 100\n",
    "step_count = 0\n",
    "log_interval = 100\n",
    "\n",
    "stop_count = 0\n",
    "best_step_count_90 = 0\n",
    "\n",
    "# valid_RMSE = np.array([])\n",
    "best_valid_RMSE_90 = 10000\n",
    "\n",
    "weight_90 = []\n",
    "\n",
    "for epoch_id in range(0, nepoch):      \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1        \n",
    "        net_90.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_90(inputs.float())        \n",
    "        loss = loss_fn(outputs.float(), targets.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(list(net.parameters()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_SSE = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                targets = targets.reshape((-1, 1))\n",
    "                outputs = net_90(inputs)\n",
    "                cn_loss = loss_fn(outputs, targets)\n",
    "                valid_SSE += cn_loss.item()\n",
    "\n",
    "            valid_tem_rmse = (valid_SSE/46371)**(1/2)\n",
    "            # valid_RMSE = np.append(valid_RMSE, valid_tem_rmse)\n",
    "\n",
    "        if valid_tem_rmse < best_valid_RMSE_90:\n",
    "          best_valid_RMSE_90 = valid_tem_rmse\n",
    "          best_step_count_90 = step_count\n",
    "          stop_count = 0\n",
    "          weight_90 = net_90.parameters\n",
    "          # print(weight)\n",
    "        else:\n",
    "          stop_count += 1\n",
    "          print(stop_count)\n",
    "        \n",
    "        if stop_count == 5000:\n",
    "          break \n",
    "    if stop_count == 5000:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZA5h9cp6faPX",
    "outputId": "66704178-61ef-40ed-88a9-c0510eaaffdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4464\n"
     ]
    }
   ],
   "source": [
    "print(best_step_count_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u6H9LYw85cb",
    "outputId": "54b605a9-be74-434d-c96d-4d54233f7490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE(H=90) = 8.967312\n"
     ]
    }
   ],
   "source": [
    "net_90.apply(weight_90)\n",
    "\n",
    "with torch.no_grad():\n",
    "  test_SSE_90 = 0\n",
    "  for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    targets = targets.reshape((-1, 1))\n",
    "    outputs = net_90(inputs)\n",
    "    cn_loss = loss_fn(outputs, targets)\n",
    "    test_SSE_90 += cn_loss.item()\n",
    "\n",
    "  test_rmse_90 = (test_SSE_90/51630)**(1/2)\n",
    "\n",
    "print(\"Test RMSE(H=90) = %f\" % test_rmse_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBbenTrlKtAB"
   },
   "source": [
    "H = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gy9fWxEqIWtf"
   },
   "outputs": [],
   "source": [
    "D_in = trainset.Xnp.shape[1]\n",
    "H = 180\n",
    "D_out = 1\n",
    "\n",
    "net_180 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),  \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, D_out)\n",
    ")\n",
    "# convert everything to float precision. \n",
    "net_180 = net_180.float()\n",
    "# move the model to device (i.e., cpu or gpu)\n",
    "net_180 = net_180.to(device)\n",
    "\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(net_180.parameters(), lr=0.00001)\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "nepoch = 100\n",
    "step_count = 0\n",
    "log_interval = 100\n",
    "\n",
    "stop_count = 0\n",
    "best_step_count_180 = 0\n",
    "\n",
    "# valid_RMSE = np.array([])\n",
    "best_valid_RMSE_180 = 10000\n",
    "\n",
    "weight_180 = []\n",
    "\n",
    "for epoch_id in range(0, nepoch):      \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1        \n",
    "        net_180.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_180(inputs.float())        \n",
    "        loss = loss_fn(outputs.float(), targets.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(list(net.parameters()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_SSE = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                targets = targets.reshape((-1, 1))\n",
    "                outputs = net_180(inputs)\n",
    "                cn_loss = loss_fn(outputs, targets)\n",
    "                valid_SSE += cn_loss.item()\n",
    "\n",
    "            valid_tem_rmse = (valid_SSE/46371)**(1/2)\n",
    "            # valid_RMSE = np.append(valid_RMSE, valid_tem_rmse)\n",
    "\n",
    "        if valid_tem_rmse < best_valid_RMSE_180:\n",
    "          best_valid_RMSE_180 = valid_tem_rmse\n",
    "          best_step_count_180 = step_count\n",
    "          stop_count = 0\n",
    "          weight_180 = net_180.parameters\n",
    "          # print(weight)\n",
    "        else:\n",
    "          stop_count += 1\n",
    "          print(stop_count)\n",
    "        \n",
    "        if stop_count == 5000:\n",
    "          break \n",
    "    if stop_count == 5000:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzTJFFzpmq0P",
    "outputId": "2a7aed51-fcbc-4022-e5b2-97ee3ac64ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3486\n"
     ]
    }
   ],
   "source": [
    "print(best_step_count_180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HufuTUIxMCHa",
    "outputId": "e033b38e-736e-4b07-8686-571dba424ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE(H=180) = 9.123229\n"
     ]
    }
   ],
   "source": [
    "net_180.apply(weight_180)\n",
    "\n",
    "with torch.no_grad():\n",
    "  test_SSE_180 = 0\n",
    "  for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    targets = targets.reshape((-1, 1))\n",
    "    outputs = net_180(inputs)\n",
    "    cn_loss = loss_fn(outputs, targets)\n",
    "    test_SSE_180 += cn_loss.item()\n",
    "\n",
    "  test_rmse_180 = (test_SSE_180/51630)**(1/2)\n",
    "\n",
    "print(\"Test RMSE(H=180) = %f\" % test_rmse_180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utWXm1u_oipu"
   },
   "source": [
    "Test RMSE(H=45) = 8.867488 < Test RMSE(H=90) = 8.967312 < Test RMSE(H=180) = 9.123229\n",
    "\n",
    "\n",
    "best_step_count_180 = 3486 < best_step_count_90 = 4464 < best_step_count = 5072\n",
    "\n",
    "\n",
    "代表H越大，RMSE越大，越早碰到最小值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OePeYFP4T7Hj"
   },
   "source": [
    "# A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "g0Bj4Y0BMMLF",
    "outputId": "be773bd9-ca85-464f-bb2b-82f636ab051c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When H=45 and Weight Decay=0.1 , test_rmse is 8.872259101123923\n",
      "When H=45 and Weight Decay=0.2 , test_rmse is 8.867624350134472\n",
      "When H=45 and Weight Decay=0.4 , test_rmse is 8.847407012554687\n",
      "When H=90 and Weight Decay=0.1 , test_rmse is 9.048492780780665\n",
      "When H=90 and Weight Decay=0.2 , test_rmse is 8.941541186287406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6b9cdcf58fcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mvalid_SSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-b0fbf6ea8b05>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;34m'Denotes the total number of samples'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;34m'Generates one sample of data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXnp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in [45, 90, 180]:\n",
    "  for j in [0.1, 0.2, 0.4]:\n",
    "    D_in = trainset.Xnp.shape[1]\n",
    "    H = i\n",
    "    D_out = 1\n",
    "\n",
    "    net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(D_in, H),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H, D_out)\n",
    "    )\n",
    "    # convert everything to float precision. \n",
    "    net = net.float()\n",
    "    # move the model to device (i.e., cpu or gpu)\n",
    "    net = net.to(device)\n",
    "\n",
    "\n",
    "    # define the optimizer\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, weight_decay=j)\n",
    "    loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    nepoch = 100\n",
    "    step_count = 0\n",
    "    log_interval = 100\n",
    "\n",
    "    stop_count = 0\n",
    "    best_step_count = 0\n",
    "\n",
    "    # valid_RMSE = np.array([])\n",
    "    best_valid_RMSE = 10000\n",
    "\n",
    "    weight = []\n",
    "\n",
    "    for epoch_id in range(0, nepoch):      \n",
    "        for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "            #reshape target to two-dimensional array\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            step_count += 1        \n",
    "            net.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs.float())        \n",
    "            loss = loss_fn(outputs.float(), targets.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(list(net.parameters()))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_SSE = 0\n",
    "                for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    targets = targets.reshape((-1, 1))\n",
    "                    outputs = net(inputs)\n",
    "                    cn_loss = loss_fn(outputs, targets)\n",
    "                    valid_SSE += cn_loss.item()\n",
    "\n",
    "                valid_tem_rmse = (valid_SSE/46371)**(1/2)\n",
    "                # valid_RMSE = np.append(valid_RMSE, valid_tem_rmse)\n",
    "\n",
    "            if valid_tem_rmse < best_valid_RMSE:\n",
    "              best_valid_RMSE = valid_tem_rmse\n",
    "              best_step_count = step_count\n",
    "              stop_count = 0\n",
    "              weight = net.parameters\n",
    "              # print(weight)\n",
    "            else:\n",
    "              stop_count += 1\n",
    "              # print(stop_count)\n",
    "            \n",
    "            if stop_count == 5000:\n",
    "              break \n",
    "        if stop_count == 5000:\n",
    "          break\n",
    "\n",
    "    net.apply(weight)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      test_SSE = 0\n",
    "      for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        outputs = net(inputs)\n",
    "        cn_loss = loss_fn(outputs, targets)\n",
    "        test_SSE += cn_loss.item()\n",
    "\n",
    "      test_rmse = (test_SSE/51630)**(1/2)\n",
    "\n",
    "    print(\"When H=\" + str(i) + \" and Weight Decay=\" + str(j) + \" , test_rmse is \" + str(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYqOgUAhTsyl"
   },
   "source": [
    "程式碼已經完成，但沒能及時跑出全部資料。以現有的資訊來看H越大時Test RMSE越大，而當Weight Decay變大時，Test RMSE則會變小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lgeeKuqV2tj"
   },
   "source": [
    "# A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gl0K0EFcTlvk"
   },
   "outputs": [],
   "source": [
    "D_in = trainset.Xnp.shape[1]\n",
    "H = 90\n",
    "\n",
    "D_out = 1\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),  \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(H, D_out)\n",
    ")\n",
    "# convert everything to float precision. \n",
    "net = net.float()\n",
    "# move the model to device (i.e., cpu or gpu)\n",
    "net = net.to(device)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "\n",
    "nepoch = 100\n",
    "step_count = 0\n",
    "log_interval = 100\n",
    "\n",
    "SSE = 0\n",
    "MSE = 0\n",
    "stop_count = 0\n",
    "best_step_count = 0\n",
    "\n",
    "train_RMSE = np.array([])\n",
    "valid_RMSE = np.array([])\n",
    "best_valid_RMSE = 10000\n",
    "\n",
    "weight = []\n",
    "\n",
    "for epoch_id in range(0, nepoch):      \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1        \n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.float())        \n",
    "        loss = loss_fn(outputs.float(), targets.float())\n",
    "\n",
    "        SSE += loss.item()\n",
    "        RMSE = (SSE/(step_count*1000))**(1/2)\n",
    "        train_RMSE = np.append(train_RMSE, RMSE)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(list(net.parameters()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_SSE = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                targets = targets.reshape((-1, 1))\n",
    "                outputs = net(inputs)\n",
    "                cn_loss = loss_fn(outputs, targets)\n",
    "                valid_SSE += cn_loss.item()\n",
    "\n",
    "            valid_tem_rmse = (valid_SSE/46371)**(1/2)\n",
    "            valid_RMSE = np.append(valid_RMSE, valid_tem_rmse)\n",
    "\n",
    "        # if step_count % log_interval == 0:            \n",
    "            # print(\"Epoch %d Step %d Loss = %.3f (minibatch size = %d)\" % (epoch_id, step_count, loss.item(), len(targets)))\n",
    "            # print(RMSE)\n",
    "            # print(valid_tem_rmse)\n",
    "\n",
    "        if valid_tem_rmse < best_valid_RMSE:\n",
    "          best_valid_RMSE = valid_tem_rmse\n",
    "          best_step_count = step_count\n",
    "          stop_count = 0\n",
    "          weight = net.parameters\n",
    "          # print(weight)\n",
    "        else:\n",
    "          stop_count += 1\n",
    "          # print(stop_count)\n",
    "\n",
    "        if stop_count == 5000:\n",
    "          break\n",
    "    if stop_count == 5000:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7Cp0bpTgxmC",
    "outputId": "d4906e17-da4b-46a1-9117-fd5dbd2ea105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12851\n"
     ]
    }
   ],
   "source": [
    "print(best_step_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6mtwgBmgraG",
    "outputId": "d1bcdc04-e283-4e36-e406-71b87ab9df54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3098\n"
     ]
    }
   ],
   "source": [
    "print(stop_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPeKPeCCg06C"
   },
   "source": [
    "由於來不及跑完，我先中止上面執行結果，畫出圖形。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "Dnl2pX7eWdA0",
    "outputId": "848f3e0f-acd6-484f-f8c3-1fb98c049694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(valid_RMSE)), valid_RMSE, label='Validation')\n",
    "plt.plot(range(len(train_RMSE)), train_RMSE, label='Training')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P2FDcLMhLlj"
   },
   "source": [
    "這是Validation RMSE的起伏變化較小，兩種RMSE都已於2000多就開始趨近於平緩，但是Training RMSE始終都比較高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mP_HIKivWjQg",
    "outputId": "e68bc32b-2cce-49cf-810b-baf9e3d36c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE(H=90) = 9.031952\n"
     ]
    }
   ],
   "source": [
    "net.apply(weight)\n",
    "\n",
    "with torch.no_grad():\n",
    "  test_SSE = 0\n",
    "  for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    targets = targets.reshape((-1, 1))\n",
    "    outputs = net(inputs)\n",
    "    cn_loss = loss_fn(outputs, targets)\n",
    "    test_SSE += cn_loss.item()\n",
    "\n",
    "  test_rmse = (test_SSE/51630)**(1/2)\n",
    "print(\"Test RMSE(H=90) = %f\" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpiEG1rbZmYa"
   },
   "source": [
    "# A6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "OT-WrIRQeJhu",
    "outputId": "742b569a-afc8-43af-8012-125956eed32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE(H=20) = 9.393714\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-149280422b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m               \u001b[0mvalid_SSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m               \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                   \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b0fbf6ea8b05>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m'Generates one sample of data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXnp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYnp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in [20, 45, 180, 360]:\n",
    "  D_in = trainset.Xnp.shape[1]\n",
    "  H = i\n",
    "\n",
    "  D_out = 1\n",
    "  use_cuda = torch.cuda.is_available()\n",
    "\n",
    "  net = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),  \n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.5),\n",
    "          torch.nn.Linear(H, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.5),\n",
    "          torch.nn.Linear(H, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.5),\n",
    "          torch.nn.Linear(H, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.5),\n",
    "          torch.nn.Linear(H, D_out)\n",
    "  )\n",
    "  # convert everything to float precision. \n",
    "  net = net.float()\n",
    "  # move the model to device (i.e., cpu or gpu)\n",
    "  net = net.to(device)\n",
    "\n",
    "  # define the optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "  loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "\n",
    "  nepoch = 100\n",
    "  step_count = 0\n",
    "  log_interval = 100\n",
    "\n",
    "  SSE = 0\n",
    "  MSE = 0\n",
    "  stop_count = 0\n",
    "  best_step_count = 0\n",
    "\n",
    "  train_RMSE = np.array([])\n",
    "  valid_RMSE = np.array([])\n",
    "  best_valid_RMSE = 10000\n",
    "\n",
    "  weight = []\n",
    "\n",
    "  for epoch_id in range(0, nepoch):      \n",
    "      for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "          #reshape target to two-dimensional array\n",
    "          targets = targets.reshape((-1, 1))\n",
    "          step_count += 1        \n",
    "          net.train()\n",
    "          inputs, targets = inputs.to(device), targets.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = net(inputs.float())        \n",
    "          loss = loss_fn(outputs.float(), targets.float())\n",
    "\n",
    "          SSE += loss.item()\n",
    "          RMSE = (SSE/(step_count*1000))**(1/2)\n",
    "          train_RMSE = np.append(train_RMSE, RMSE)\n",
    "\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          # print(list(net.parameters()))\n",
    "\n",
    "          with torch.no_grad():\n",
    "              valid_SSE = 0\n",
    "              for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "                  inputs, targets = inputs.to(device), targets.to(device)\n",
    "                  targets = targets.reshape((-1, 1))\n",
    "                  outputs = net(inputs)\n",
    "                  cn_loss = loss_fn(outputs, targets)\n",
    "                  valid_SSE += cn_loss.item()\n",
    "\n",
    "              valid_tem_rmse = (valid_SSE/46371)**(1/2)\n",
    "              valid_RMSE = np.append(valid_RMSE, valid_tem_rmse)\n",
    "\n",
    "          # if step_count % log_interval == 0:            \n",
    "              # print(\"Epoch %d Step %d Loss = %.3f (minibatch size = %d)\" % (epoch_id, step_count, loss.item(), len(targets)))\n",
    "              # print(RMSE)\n",
    "              # print(valid_tem_rmse)\n",
    "\n",
    "          if valid_tem_rmse < best_valid_RMSE:\n",
    "            best_valid_RMSE = valid_tem_rmse\n",
    "            best_step_count = step_count\n",
    "            stop_count = 0\n",
    "            weight = net.parameters\n",
    "            # print(weight)\n",
    "          else:\n",
    "            stop_count += 1\n",
    "            # print(stop_count)\n",
    "\n",
    "          if stop_count == 5000:\n",
    "            break\n",
    "      if stop_count == 5000:\n",
    "        break\n",
    "  net.apply(weight)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    test_SSE = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      targets = targets.reshape((-1, 1))\n",
    "      outputs = net(inputs)\n",
    "      cn_loss = loss_fn(outputs, targets)\n",
    "      test_SSE += cn_loss.item()\n",
    "\n",
    "    test_rmse = (test_SSE/51630)**(1/2)\n",
    "  print(\"Test RMSE(H=%d) = %f\" % (i, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeuY9GJ2eN9D"
   },
   "source": [
    "Test RMSE(H=20) = 9.393714。程式碼已經完成，但沒能及時跑出全部資料。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jf5JvktKc9cK"
   },
   "source": [
    "# A7-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "vG2V97FWc-Qx",
    "outputId": "75c4c7fd-89de-458a-fe5a-9ee2b11f0359"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-cfd1ba1710c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mvalid_SSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D_in = trainset.Xnp.shape[1]\n",
    "H = 90\n",
    "\n",
    "D_out = 1\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),  \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(H, D_out)\n",
    ")\n",
    "# convert everything to float precision. \n",
    "net = net.float()\n",
    "# move the model to device (i.e., cpu or gpu)\n",
    "net = net.to(device)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_fn_2 = torch.nn.MSELoss(reduction=\"sum\")\n",
    "loss_fn_1 = torch.nn.L1Loss(reduction=\"sum\")\n",
    "\n",
    "\n",
    "nepoch = 100\n",
    "step_count = 0\n",
    "log_interval = 100\n",
    "\n",
    "SSE = 0\n",
    "MSE = 0\n",
    "stop_count = 0\n",
    "best_step_count = 0\n",
    "\n",
    "train_RMSE = np.array([])\n",
    "valid_RMSE = np.array([])\n",
    "best_loss = 10000000000000000000000\n",
    "\n",
    "weight = []\n",
    "\n",
    "for epoch_id in range(0, nepoch):      \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1        \n",
    "        net.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.float())        \n",
    "        loss = 0.5*loss_fn_1(outputs.float(), targets.float()) + 0.5*loss_fn_2(outputs.float(), targets.float())\n",
    "\n",
    "        SSE += loss.item()\n",
    "        RMSE = (SSE/(step_count*1000))**(1/2)\n",
    "        train_RMSE = np.append(train_RMSE, RMSE)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(list(net.parameters()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_SSE = 0\n",
    "            loss = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                targets = targets.reshape((-1, 1))\n",
    "                outputs = net(inputs)\n",
    "                cn_loss = loss_fn_2(outputs, targets)\n",
    "                valid_SSE += cn_loss.item()\n",
    "                cn_loss_mix = 0.5*loss_fn_1(outputs.float(), targets.float()) + 0.5*loss_fn_2(outputs.float(), targets.float())\n",
    "                loss += cn_loss_mix\n",
    "\n",
    "            valid_tem_rmse = (valid_SSE/46371)**(1/2)\n",
    "            valid_RMSE = np.append(valid_RMSE, valid_tem_rmse)\n",
    "\n",
    "        # if step_count % log_interval == 0:            \n",
    "            # print(\"Epoch %d Step %d Loss = %.3f (minibatch size = %d)\" % (epoch_id, step_count, loss.item(), len(targets)))\n",
    "            # print(RMSE)\n",
    "            # print(valid_tem_rmse)\n",
    "\n",
    "        if loss.item() < best_loss:\n",
    "          best_loss = loss\n",
    "          best_step_count = step_count\n",
    "          stop_count = 0\n",
    "          weight = net.parameters\n",
    "          # print(weight)\n",
    "        else:\n",
    "          stop_count += 1\n",
    "          # print(stop_count)\n",
    "\n",
    "        if stop_count == 5000:\n",
    "          break\n",
    "    if stop_count == 5000:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yJRQUkviDRR",
    "outputId": "ec3de11b-ba43-48dc-9b52-934cba433b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "14599\n"
     ]
    }
   ],
   "source": [
    "print(stop_count)\n",
    "print(best_step_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5z6X_pdBiydH"
   },
   "source": [
    "還來不及做完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "-4IRGuSVhl6B",
    "outputId": "d45e329c-4c02-4a02-ce0c-4efbe89bbe6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(valid_RMSE)), valid_RMSE, label='Validation')\n",
    "plt.plot(range(len(train_RMSE)), train_RMSE, label='Training')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Wf5tzXficRL"
   },
   "source": [
    "Validation RMSE始終比Training RMSE高出幾乎固定的量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npi6hk_kjVJl",
    "outputId": "4621e688-58e7-4407-bc24-d70b5f33fa3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE(H=90) = 9.016850\n"
     ]
    }
   ],
   "source": [
    "net.apply(weight)\n",
    "\n",
    "with torch.no_grad():\n",
    "  test_SSE = 0\n",
    "  for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    targets = targets.reshape((-1, 1))\n",
    "    outputs = net(inputs)\n",
    "    cn_loss = loss_fn_2(outputs, targets)\n",
    "    test_SSE += cn_loss.item()\n",
    "\n",
    "  test_rmse = (test_SSE/51630)**(1/2)\n",
    "print(\"Test RMSE(H=90) = %f\" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XJyv60Bd7tj"
   },
   "source": [
    "# A7-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7PvUDPkuqyF"
   },
   "outputs": [],
   "source": [
    "for z in [0, 0.1, 0.9]:\n",
    "  D_in = trainset.Xnp.shape[1]\n",
    "  H = 90\n",
    "\n",
    "  D_out = 1\n",
    "\n",
    "  net = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),  \n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.5),\n",
    "          torch.nn.Linear(H, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.5),\n",
    "          torch.nn.Linear(H, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.5),\n",
    "          torch.nn.Linear(H, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.5),\n",
    "          torch.nn.Linear(H, D_out)\n",
    "  )\n",
    "  # convert everything to float precision. \n",
    "  net = net.float()\n",
    "  # move the model to device (i.e., cpu or gpu)\n",
    "  net = net.to(device)\n",
    "\n",
    "  # define the optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "  loss_fn_2 = torch.nn.MSELoss(reduction=\"sum\")\n",
    "  loss_fn_1 = torch.nn.L1Loss(reduction=\"sum\")\n",
    "\n",
    "\n",
    "  nepoch = 100\n",
    "  step_count = 0\n",
    "  log_interval = 100\n",
    "\n",
    "  stop_count = 0\n",
    "  best_step_count = 0\n",
    "\n",
    "  best_loss = 10000000000000000000000\n",
    "\n",
    "  weight = []\n",
    "\n",
    "  for epoch_id in range(0, nepoch):      \n",
    "      for batch_idx, (inputs, targets) in enumerate(subtrainloader):\n",
    "          #reshape target to two-dimensional array\n",
    "          targets = targets.reshape((-1, 1))\n",
    "          step_count += 1        \n",
    "          net.train()\n",
    "          inputs, targets = inputs.to(device), targets.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = net(inputs.float())        \n",
    "          loss = z*loss_fn_1(outputs.float(), targets.float()) + (1-z)*loss_fn_2(outputs.float(), targets.float())\n",
    "\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          # print(list(net.parameters()))\n",
    "\n",
    "          with torch.no_grad():\n",
    "              loss = 0\n",
    "              for batch_idx, (inputs, targets) in enumerate(validloader):            \n",
    "                  inputs, targets = inputs.to(device), targets.to(device)\n",
    "                  targets = targets.reshape((-1, 1))\n",
    "                  outputs = net(inputs)\n",
    "                  cn_loss = loss_fn_2(outputs, targets)\n",
    "                  valid_SSE += cn_loss.item()\n",
    "                  cn_loss_mix = z*loss_fn_1(outputs.float(), targets.float()) + (1-z)*loss_fn_2(outputs.float(), targets.float())\n",
    "                  loss += cn_loss_mix\n",
    "\n",
    "          # if step_count % log_interval == 0:            \n",
    "              # print(\"Epoch %d Step %d Loss = %.3f (minibatch size = %d)\" % (epoch_id, step_count, loss.item(), len(targets)))\n",
    "              # print(RMSE)\n",
    "              # print(valid_tem_rmse)\n",
    "\n",
    "          if loss.item() < best_loss:\n",
    "            best_loss = loss\n",
    "            best_step_count = step_count\n",
    "            stop_count = 0\n",
    "            weight = net.parameters\n",
    "            # print(weight)\n",
    "          else:\n",
    "            stop_count += 1\n",
    "            # print(stop_count)\n",
    "\n",
    "          if stop_count == 5000:\n",
    "            break\n",
    "      if stop_count == 5000:\n",
    "        break\n",
    "\n",
    "\n",
    "  net.apply(weight)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    test_SSE = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):            \n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      targets = targets.reshape((-1, 1))\n",
    "      outputs = net(inputs)\n",
    "      cn_loss = loss_fn_2(outputs, targets)\n",
    "      test_SSE += cn_loss.item()\n",
    "\n",
    "    test_rmse = (test_SSE/51630)**(1/2)\n",
    "  print(\"Test RMSE(z=%f) = %f\" % (z, test_rmse))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw4_qonlyv5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
