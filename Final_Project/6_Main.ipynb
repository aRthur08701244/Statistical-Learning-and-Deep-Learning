{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd597a16-8d9b-4441-9ff4-53bd6fc38d68",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75163f3-b07d-444d-95da-26cf673d4a1e",
   "metadata": {},
   "source": [
    "<li> 實價登錄：x_train_raw\n",
    "<li>實價登錄 + 機能：x_train_fac\n",
    "<li>實價登錄 + 機能 + 街景 + 人工標籤：x_train_fac_street\n",
    "<li>實價登錄 + 機能 + 衛星 + 人工標籤：x_train_fac_satel\n",
    "<li>實價登錄 + 機能 + 街景 + 衛星 + 人工標籤：x_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83089c0-93ac-4803-8c72-1070e05e9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678f5e52-5275-4e31-9666-2926f6067d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loading\n",
    "x_train_full = pd.read_csv('C:\\\\Users\\\\andyi\\\\OneDrive\\\\桌面\\\\x_train\\\\x_train_full.csv')\n",
    "x_train_full = x_train_full.drop(columns=['Unnamed: 0'])\n",
    "x_valid_full = pd.read_csv('C:\\\\Users\\\\andyi\\\\OneDrive\\\\桌面\\\\x_valid\\\\x_valid_full.csv')\n",
    "x_valid_full = x_valid_full.drop(columns=['Unnamed: 0'])\n",
    "x_test_full = pd.read_csv('C:\\\\Users\\\\andyi\\\\OneDrive\\\\桌面\\\\x_test\\\\x_test_full.csv')\n",
    "x_test_full = x_test_full.drop(columns=['Unnamed: 0'])\n",
    "ntrain = x_train_full.shape[0]\n",
    "nvalid = x_valid_full.shape[0]\n",
    "ntest = x_test_full.shape[0]\n",
    "X = pd.concat([x_train_full, x_valid_full, x_test_full], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461b825e-63ef-4cd6-8677-cb30be1b305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X.columns\n",
    "raw = X[col[:81]]\n",
    "fac = X[col[81:96]]\n",
    "street = X[col[96:160]]\n",
    "satellite = X[col[160:220]]\n",
    "score = X[col[220]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbdea91-bcbe-404a-b83b-4ba200ee7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization: fac, street, score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "fac = scaler.fit_transform(fac)\n",
    "street = scaler.fit_transform(street)\n",
    "score = scaler.fit_transform(np.array(score).reshape(-1,1))\n",
    "\n",
    "fac = pd.DataFrame(fac, columns=col[81:96])\n",
    "street = pd.DataFrame(street, columns=[(\"Street\" + str(i)) for i in range(1, 65)])\n",
    "score = pd.DataFrame(score, columns=[col[220]])\n",
    "satellite.columns = [(\"Sat\" + str(i)) for i in range(1, 61)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43049d9-6fed-431f-adcc-5970d9f1281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to each dataset\n",
    "\n",
    "def assign(data):\n",
    "    ALL = pd.concat([d for d in data], axis=1)\n",
    "    x_train = ALL[:ntrain]\n",
    "    x_valid = ALL[ntrain:(ntrain+nvalid)]\n",
    "    x_test = ALL[(ntrain+nvalid):]\n",
    "    return x_train, x_valid, x_test\n",
    "\n",
    "# 1. x_train_raw, x_valid_raw, x_test_raw\n",
    "x_train_raw, x_valid_raw, x_test_raw = assign([raw])\n",
    "\n",
    "# 2. x_train_fac, x_valid_fac, x_test_fac\n",
    "x_train_fac, x_valid_fac, x_test_fac = assign([raw, fac])\n",
    "\n",
    "# 3. x_train_fac_street, x_valid_fac_street, x_test_fac_street\n",
    "x_train_fac_street, x_valid_fac_street, x_test_fac_street = assign([raw, fac, street, score])\n",
    "\n",
    "# 4. x_train_fac_satel, x_valid_fac_satel, x_test_fac_satel\n",
    "x_train_fac_satel, x_valid_fac_satel, x_test_fac_satel = assign([raw, fac, satellite, score])\n",
    "\n",
    "# 5. x_train_fac_full, x_valid_fac_full, x_test_fac_full\n",
    "x_train_full, x_valid_full, x_test_full = assign([raw, fac, street, satellite, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be44fcd2-6d82-4354-bd5e-03d191021264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y\n",
    "y_train = pd.read_csv('C:\\\\Users\\\\andyi\\\\OneDrive\\\\桌面\\\\y\\\\y_train.csv')\n",
    "y_train = y_train.drop(columns=['Unnamed: 0']).to_numpy().ravel()\n",
    "y_valid = pd.read_csv('C:\\\\Users\\\\andyi\\\\OneDrive\\\\桌面\\\\y\\\\y_valid.csv')\n",
    "y_valid = y_valid.drop(columns=['Unnamed: 0']).to_numpy().ravel()\n",
    "y_test = pd.read_csv('C:\\\\Users\\\\andyi\\\\OneDrive\\\\桌面\\\\y\\\\y_test.csv')\n",
    "y_test = y_test.drop(columns=['Unnamed: 0']).to_numpy().ravel()\n",
    "y_all = np.concatenate([y_train, y_valid, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969f038-7638-4af1-b9ad-fe9de9111af8",
   "metadata": {},
   "source": [
    "## Perform Feature Selection via F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5590bbf8-ac7f-47af-98b8-d6a406f73640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (10049, 150)\n",
      "X_test: (2812, 150)\n",
      "X_valid: (1100, 150)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "def FSelect(dataset, k=100):\n",
    "    # Concatenate all data\n",
    "    all_X = pd.concat(dataset, axis=0)\n",
    "    all_Y = y_all\n",
    "\n",
    "    # F-test\n",
    "    selector = SelectKBest(f_regression, k=k)\n",
    "    all_X_new = selector.fit_transform(all_X, all_Y)\n",
    "    new_columns = selector.get_feature_names_out()\n",
    "    all_X_new = pd.DataFrame(all_X_new, columns=new_columns)\n",
    "\n",
    "    x_train = all_X_new[:ntrain]\n",
    "    x_valid = all_X_new[ntrain:(ntrain + nvalid)]\n",
    "    x_test = all_X_new[(ntrain + nvalid):]\n",
    "\n",
    "    return x_train, x_valid, x_test\n",
    "\n",
    "# 1. x_train_raw, x_valid_raw, x_test_raw: no need to fselect\n",
    "# x_train_raw, x_valid_raw, x_test_raw = FSelect([x_train_raw, x_valid_raw, x_test_raw], k=)\n",
    "\n",
    "# 2. x_train_fac, x_valid_fac, x_test_fac: no need to fselect\n",
    "# x_train_fac, x_valid_fac, x_test_fac = FSelect([x_train_fac, x_valid_fac, x_test_fac])\n",
    "\n",
    "# 3. x_train_fac_street, x_valid_fac_street, x_test_fac_street\n",
    "x_train_fac_street, x_valid_fac_street, x_test_fac_street = FSelect([x_train_fac_street, x_valid_fac_street, x_test_fac_street], k=110)\n",
    "\n",
    "# 4. x_train_fac_satel, x_valid_fac_satel, x_test_fac_satel\n",
    "x_train_fac_satel, x_valid_fac_satel, x_test_fac_satel = FSelect([x_train_fac_satel, x_valid_fac_satel, x_test_fac_satel], k=110)\n",
    "\n",
    "# 5. x_train_fac_full, x_valid_fac_full, x_test_fac_full\n",
    "x_train_full, x_valid_full, x_test_full = FSelect([x_train_full, x_valid_full, x_test_full], k=150)\n",
    "\n",
    "print(\"X_train:\", x_train_full.shape)\n",
    "print(\"X_test:\", x_test_full.shape)\n",
    "print(\"X_valid:\", x_valid_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813527d-43bb-47ac-b523-6aa9e4e20970",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b789c47-ed12-40ab-8f64-2b24777a1354",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f688a4b9-15c6-4f27-bbb0-c5c31e274208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def Ridgereg(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global ridge\n",
    "    ridge = Ridge()\n",
    "    col = X_train.columns\n",
    "    tune_params = {'alpha':np.arange(1, 5, 0.1)}\n",
    "    gd = GridSearchCV(ridge, tune_params)\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    alpha = gd.best_params_[\"alpha\"]\n",
    "    print(\"best alpha:\", alpha)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_valid_train, y_valid_train)\n",
    "    pred = ridge.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    # Find the most important 10 features\n",
    "    abs_coef_idx = np.flip(np.argsort(np.absolute(ridge.coef_)))\n",
    "    print(\"The 10 most important features:\")\n",
    "    for i in range(10):\n",
    "        if i != 9:\n",
    "            print(col[abs_coef_idx[i]], end=\", \")\n",
    "        else:\n",
    "            print(col[abs_coef_idx[i]])\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b1745-7c7d-4cde-a0df-00b4072434c2",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c357e9-228a-430c-b739-9eecae44ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def Lassoreg(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global lasso\n",
    "    col = X_train.columns\n",
    "    lasso = Lasso()\n",
    "    tune_params = {'alpha':np.arange(1, 5, 0.1)}\n",
    "    gd = GridSearchCV(lasso, tune_params)\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    alpha = gd.best_params_[\"alpha\"]\n",
    "    print(\"best alpha:\", alpha)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_valid_train, y_valid_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    # Find the most important 10 features\n",
    "    abs_coef_idx = np.flip(np.argsort(np.absolute(lasso.coef_)))\n",
    "    print(\"The 10 most important features:\")\n",
    "    for i in range(10):\n",
    "        if i != 9:\n",
    "            print(col[abs_coef_idx[i]], end=\", \")\n",
    "        else:\n",
    "            print(col[abs_coef_idx[i]])\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882d30a-cf12-4818-a76f-14f21e947044",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "badae988-2cfc-4169-abcd-127fd34a883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def KNN(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global knn\n",
    "    knn = KNeighborsRegressor()\n",
    "    tune_params = {'n_neighbors':range(1, 31), 'weights':['distance', 'uniform'],\n",
    "                   'leaf_size':range(1, 20)}\n",
    "    gd = GridSearchCV(knn, tune_params)\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    n_neighbors = gd.best_params_[\"n_neighbors\"]\n",
    "    print(\"best n_neighbors:\", n_neighbors)\n",
    "    weights = gd.best_params_[\"weights\"]\n",
    "    print(\"best weights:\", weights)\n",
    "    leaf_size = gd.best_params_[\"leaf_size\"]\n",
    "    print(\"best leaf_size:\", leaf_size)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights, leaf_size=leaf_size)\n",
    "    knn.fit(X_valid_train, y_valid_train)\n",
    "    pred = knn.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37fbf13-3e5a-48e4-99d4-0eaa4f1bb487",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c85eef0-ce32-4c53-b3b7-c8149bf2e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def RandomForest(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global RF\n",
    "    RF = RandomForestRegressor(random_state=439)\n",
    "    tune_params = {'n_estimators':range(200, 300, 20)}\n",
    "    gd = GridSearchCV(RF, tune_params)\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    n_estimators = gd.best_params_[\"n_estimators\"]\n",
    "    print(\"best n_estimators:\", n_estimators)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    RF = RandomForestRegressor(n_estimators=n_estimators, oob_score=True, random_state=439)\n",
    "    RF.fit(X_valid_train, y_valid_train)\n",
    "    pred = RF.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    # printing the 10 most important features\n",
    "    importance = RF.feature_importances_\n",
    "    idx = np.flip(np.argsort(importance))\n",
    "    important_10feat = X_train.columns[idx[:10]]\n",
    "    print(\"The 10 most important features:\")\n",
    "    for i in range(10):\n",
    "        if i != 9:\n",
    "            print(important_10feat[i], end=\", \")\n",
    "        else:\n",
    "            print(important_10feat[i])\n",
    "    return RF.oob_score_, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d6dd6-8411-4cad-98a1-e38d2bca575b",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe67e470-5ede-4b37-a422-8f7b9dfb1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def Bagging(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global bagging\n",
    "    bagging = BaggingRegressor(random_state=439)\n",
    "    tune_params = {'n_estimators':range(200, 300, 20)}\n",
    "    gd = GridSearchCV(bagging, tune_params)\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    n_estimators = gd.best_params_[\"n_estimators\"]\n",
    "    print(\"best n_estimators:\", n_estimators)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    bagging = BaggingRegressor(n_estimators=n_estimators,\n",
    "                               oob_score=True,\n",
    "                               random_state=439)\n",
    "    bagging.fit(X_valid_train, y_valid_train)\n",
    "    pred = bagging.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    return bagging.oob_score_, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43401e-fb46-4706-a4ca-316b0bbdc6f5",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "678c5ff0-895c-48f6-80cd-fb655ea47eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def DecisionTree(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global DT\n",
    "    DT = DecisionTreeRegressor(random_state=439)\n",
    "    tune_params = {'criterion':[\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "                   'max_depth':range(5, 20),\n",
    "                   'min_samples_split':range(2, 10)}\n",
    "    gd = GridSearchCV(DT, tune_params, scoring='neg_root_mean_squared_error')\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    criterion = gd.best_params_[\"criterion\"]\n",
    "    max_depth = gd.best_params_[\"max_depth\"]\n",
    "    min_samples_split = gd.best_params_[\"min_samples_split\"]\n",
    "    print(\"best criterion:\", criterion)\n",
    "    print(\"best max_depth:\", max_depth)\n",
    "    print(\"best min_samples_split:\", min_samples_split)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    DT = DecisionTreeRegressor(criterion=criterion, max_depth=max_depth,\n",
    "                               min_samples_split=min_samples_split, random_state=439)\n",
    "    DT.fit(X_valid_train, y_valid_train)\n",
    "    pred = DT.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    # printing the 10 most important features\n",
    "    importance = DT.feature_importances_\n",
    "    idx = np.flip(np.argsort(importance))\n",
    "    important_10feat = X_train.columns[idx[:10]]\n",
    "    print(\"The 10 most important features:\")\n",
    "    for i in range(10):\n",
    "        if i != 9:\n",
    "            print(important_10feat[i], end=\", \")\n",
    "        else:\n",
    "            print(important_10feat[i])\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9cea63-69a1-430c-a948-950eda1ab544",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deb888f0-9252-41ae-bc8c-2a5bf07c7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def GBoosting(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global GBDT\n",
    "    GBDT = GradientBoostingRegressor(random_state=439)\n",
    "    tune_params = {'loss':[\"squared_error\", \"huber\", \"absolute_error\", \"quantile\"],\n",
    "                   'learning_rate':[0.01, 0.1, 0.2, 0.4],\n",
    "                   'n_estimators':range(120, 200, 20)}\n",
    "    gd = GridSearchCV(GBDT, tune_params, scoring='neg_root_mean_squared_error')\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    loss = gd.best_params_[\"loss\"]\n",
    "    learning_rate = gd.best_params_[\"learning_rate\"]\n",
    "    n_estimators = gd.best_params_[\"n_estimators\"]\n",
    "    print(\"best loss:\", loss)\n",
    "    print(\"best learning_rate:\", learning_rate)\n",
    "    print(\"best n_estimators:\", n_estimators)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    GBDT = GradientBoostingRegressor(loss=loss, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "                                     random_state=439)\n",
    "    GBDT.fit(X_valid_train, y_valid_train)\n",
    "    pred = GBDT.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    # printing the 10 most important features\n",
    "    importance = GBDT.feature_importances_\n",
    "    idx = np.flip(np.argsort(importance))\n",
    "    important_10feat = X_train.columns[idx[:10]]\n",
    "    print(\"The 10 most important features:\")\n",
    "    for i in range(10):\n",
    "        if i != 9:\n",
    "            print(important_10feat[i], end=\", \")\n",
    "        else:\n",
    "            print(important_10feat[i])\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4385f00-df06-415c-88e3-0476ff60cc90",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba68e53-ab4c-47a6-9835-cb16a9230588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def AdaBoost(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global ada\n",
    "    ada = AdaBoostRegressor(random_state=439)\n",
    "    tune_params = {'loss':[\"linear\", \"square\", \"exponential\"],\n",
    "                   'learning_rate':[0.1, 0.3, 0.5, 0.8, 1, 1.5, 2, 2.5, 3],\n",
    "                   'n_estimators':range(10, 150, 10)}\n",
    "    gd = GridSearchCV(ada, tune_params, scoring='neg_root_mean_squared_error')\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    loss = gd.best_params_[\"loss\"]\n",
    "    learning_rate = gd.best_params_[\"learning_rate\"]\n",
    "    n_estimators = gd.best_params_[\"n_estimators\"]\n",
    "    print(\"best loss:\", loss)\n",
    "    print(\"best learning_rate:\", learning_rate)\n",
    "    print(\"best n_estimators:\", n_estimators)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    ada = AdaBoostRegressor(loss=loss, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "                            random_state=439)\n",
    "    ada.fit(X_valid_train, y_valid_train)\n",
    "    pred = ada.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    # printing the 10 most important features\n",
    "    importance = ada.feature_importances_\n",
    "    idx = np.flip(np.argsort(importance))\n",
    "    important_10feat = X_train.columns[idx[:10]]\n",
    "    print(\"The 10 most important features:\")\n",
    "    for i in range(10):\n",
    "        if i != 9:\n",
    "            print(important_10feat[i], end=\", \")\n",
    "        else:\n",
    "            print(important_10feat[i])\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5108756d-62f5-4f5c-9a33-d3530cb4c3b2",
   "metadata": {},
   "source": [
    "## Supported Vector Machine Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e6f517-8748-4779-af70-a5c44b2f8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def SVM(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global svr\n",
    "    svr = SVR()\n",
    "    tune_params = {'kernel':[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                   'C':np.arange(0.1, 3, 0.1)}\n",
    "    gd = GridSearchCV(svr, tune_params, scoring='neg_root_mean_squared_error')\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    kernel = gd.best_params_[\"kernel\"]\n",
    "    C = gd.best_params_[\"C\"]\n",
    "    print(\"best kernel:\", kernel)\n",
    "    print(\"best C:\", C)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    svr = SVR(kernel=kernel, C=C)\n",
    "    svr.fit(X_valid_train, y_valid_train)\n",
    "    pred = svr.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea4e41-b72a-42ff-92e3-16e5ab0d7b2f",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61810f3b-6f05-4eb1-b79c-83ac3bbb7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def SGD(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global sgd\n",
    "    sgd = SGDRegressor()\n",
    "    tune_params = {'loss':[\"squared_error\", \"huber\", \"epsilon_insensitive\"],\n",
    "                   'penalty':[\"l2\", \"l1\"],\n",
    "                   'alpha':np.logspace(-6, 1, 8, base=10)}\n",
    "    gd = GridSearchCV(sgd, tune_params, scoring='neg_root_mean_squared_error')\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    loss = gd.best_params_[\"loss\"]\n",
    "    penalty = gd.best_params_[\"penalty\"]\n",
    "    alpha = gd.best_params_[\"alpha\"]\n",
    "    print(\"best loss:\", loss)\n",
    "    print(\"best penalty:\", penalty)\n",
    "    print(\"best alpha:\", alpha)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    sgd = SGDRegressor(loss=loss, penalty=penalty, alpha=alpha)\n",
    "    sgd.fit(X_valid_train, y_valid_train)\n",
    "    pred = sgd.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfea2ae-9954-4877-b0ca-c52905ecf2d7",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5767e37-8ff4-48aa-b02d-8775d2776646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def MLP(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global mlp\n",
    "    mlp = MLPRegressor(early_stopping=True, hidden_layer_sizes=360)\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    mlp.fit(X_valid_train, y_valid_train)\n",
    "    pred = mlp.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07496ee3-de3c-46c0-8fd0-4bedc14ff7df",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adcd20d3-7303-4a2c-b632-6f4c56e63425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def XGB(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global xgb\n",
    "    xgb = XGBRegressor()\n",
    "    tune_params = {\"n_estimators\":range(1, 50)}\n",
    "    gd = GridSearchCV(xgb, tune_params, scoring='neg_root_mean_squared_error')\n",
    "    gd.fit(X_valid, y_valid)\n",
    "\n",
    "    n_estimators = gd.best_params_[\"n_estimators\"]\n",
    "    print(\"best n_estimators:\", n_estimators)\n",
    "    print(\"==========\")\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    xgb = XGBRegressor(n_estimators=n_estimators)\n",
    "    xgb.fit(X_valid_train, y_valid_train)\n",
    "    pred = xgb.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94194090-6dc9-4e17-98a4-ad75f1bbf943",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9845c55-4c71-4aa8-87f4-df41cf23eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def Stacking(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    ests = [\n",
    "            (\"Random Forest\", RF),\n",
    "            (\"Bagging\", bagging),\n",
    "            (\"Gradient Boosting\", GBDT),\n",
    "            (\"KNN\", knn),\n",
    "            (\"SGD\", sgd),\n",
    "            (\"Ridge\", ridge),\n",
    "            (\"XGB\", xgb)\n",
    "           ]\n",
    "    stacking = StackingRegressor(estimators=ests)\n",
    "\n",
    "    X_valid_train = pd.concat([X_valid, X_train], axis=0)\n",
    "    y_valid_train = np.concatenate([y_valid, y_train], axis=0)\n",
    "\n",
    "    stacking.fit(X_valid_train, y_valid_train)\n",
    "\n",
    "    pred = stacking.predict(X_test)\n",
    "    RMSE = mean_squared_error(y_test, pred, squared=False)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a14292-9665-4800-a7f6-9eb980c30c85",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131734b3-c5d7-4d0c-a1c8-55fa1d2458c3",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "<li> 實價登錄：x_train_raw\n",
    "<li>實價登錄 + 機能：x_train_fac\n",
    "<li>實價登錄 + 機能 + 街景 + 人工標籤：x_train_fac_street\n",
    "<li>實價登錄 + 機能 + 衛星 + 人工標籤：x_train_fac_satel\n",
    "<li>實價登錄 + 機能 + 街景 + 衛星 + 人工標籤：x_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76470319-0371-4b2b-a71a-fabac06f6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf2a9e15-28f1-4f43-bcf7-e27c4643e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Solely Government Data ====\n",
      "\n",
      "||Ridge Regression||\n",
      "best alpha: 3.500000000000002\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 鄉鎮市區_萬華區, 鄉鎮市區_文山區, 鄉鎮市區_北投區, 移轉層次項目_平台, 鄉鎮市區_松山區, 主要用途_見使用執照, 鄉鎮市區_中正區, 建物型態_店面(店鋪), 使用分區_特定休閒旅館住宅專用區\n",
      "Ridge Regression | RMSE = 41474.03474987123 \n",
      "\n",
      "||Lasso Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 鄉鎮市區_萬華區, 移轉層次項目_平台, 鄉鎮市區_松山區, 鄉鎮市區_中正區, 主要用途_見使用執照, 鄉鎮市區_信義區, 移轉層次項目_騎樓, 建物型態_店面(店鋪), 鄉鎮市區_文山區\n",
      "Lasso Regression | RMSE = 41463.25751878098 \n",
      "\n",
      "||KNN||\n",
      "best n_neighbors: 6\n",
      "best weights: distance\n",
      "best leaf_size: 1\n",
      "==========\n",
      "KNN | RMSE = 40857.47617396677 \n",
      "\n",
      "||Random Forest||\n",
      "best n_estimators: 280\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 屋齡, 鄉鎮市區_大安區, 建物移轉總面積平方公尺, 土地移轉總面積平方公尺, 移轉層次, 總樓層數, 建材_鋼筋混凝土造, 鄉鎮市區_北投區, 鄉鎮市區_文山區\n",
      "Random Forest | RMSE = 35399.856584492845\n",
      "Random Forest | OOB Score = 0.6282794349825827 \n",
      "\n",
      "||Bagging||\n",
      "best n_estimators: 280\n",
      "==========\n",
      "Bagging | RMSE = 35376.00555136411\n",
      "Bagging | OOB Score = 0.62881634191952 \n",
      "\n",
      "||Decision Tree||\n",
      "best criterion: squared_error\n",
      "best max_depth: 8\n",
      "best min_samples_split: 8\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 鄉鎮市區_大安區, 屋齡, 建材_鋼筋混凝土造, 鄉鎮市區_北投區, 鄉鎮市區_文山區, 移轉層次, 鄉鎮市區_萬華區, 鄉鎮市區_松山區, 鄉鎮市區_中山區\n",
      "Decision Tree | RMSE = 43068.33701896999 \n",
      "\n",
      "||Gradient Boosting||\n",
      "best loss: huber\n",
      "best learning_rate: 0.2\n",
      "best n_estimators: 120\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 鄉鎮市區_大安區, 屋齡, 鄉鎮市區_文山區, 鄉鎮市區_北投區, 鄉鎮市區_松山區, 建物移轉總面積平方公尺, 建材_鋼筋混凝土造, 移轉層次, 鄉鎮市區_萬華區\n",
      "Gradient Boosting | RMSE = 37563.129290374236 \n",
      "\n",
      "||Ada Boosting||\n",
      "best loss: exponential\n",
      "best learning_rate: 2.5\n",
      "best n_estimators: 120\n",
      "==========\n",
      "The 10 most important features:\n",
      "土地移轉總面積平方公尺, 屋齡, 建物移轉總面積平方公尺, 移轉層次, 建物現況格局-房, 鄉鎮市區_北投區, 鄉鎮市區_大安區, 總樓層數, 鄉鎮市區_萬華區, 鄉鎮市區_內湖區\n",
      "Ada Boosting | RMSE = 51217.69947858269 \n",
      "\n",
      "||Support Vector Machine||\n",
      "best kernel: linear\n",
      "best C: 2.9000000000000004\n",
      "==========\n",
      "Support Vector Machine | RMSE = 53418.28008983501 \n",
      "\n",
      "||Stochastic Gradient Descent||\n",
      "best loss: squared_error\n",
      "best penalty: l1\n",
      "best alpha: 1e-05\n",
      "==========\n",
      "Stochastic Gradient Descent | RMSE = 41568.92345216913 \n",
      "\n",
      "||Multi-Layer Perceptron||\n",
      "Multi-Layer Perceptron | RMSE = 51500.35917481815 \n",
      "\n",
      "||XGBoost||\n",
      "best n_estimators: 22\n",
      "==========\n",
      "XGBoost | RMSE = 37365.3060352551 \n",
      "\n",
      "||Stacking||\n",
      "Stacking | RMSE = 35103.37682397514\n"
     ]
    }
   ],
   "source": [
    "# Evaluation: Solely Government Data\n",
    "print(\"==== Solely Government Data ====\\n\")\n",
    "\n",
    "print(\"||Ridge Regression||\")\n",
    "rmse = Ridgereg(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Ridge Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Lasso Regression||\")\n",
    "rmse = Lassoreg(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Lasso Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||KNN||\")\n",
    "rmse = KNN(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"KNN | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Random Forest||\")\n",
    "oob, rmse = RandomForest(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Random Forest | RMSE =\", rmse)\n",
    "print(\"Random Forest | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Bagging||\")\n",
    "oob, rmse = Bagging(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Bagging | RMSE =\", rmse)\n",
    "print(\"Bagging | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Decision Tree||\")\n",
    "rmse = DecisionTree(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Decision Tree | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Gradient Boosting||\")\n",
    "rmse = GBoosting(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Gradient Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Ada Boosting||\")\n",
    "rmse = AdaBoost(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Ada Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Support Vector Machine||\")\n",
    "rmse = SVM(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Support Vector Machine | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stochastic Gradient Descent||\")\n",
    "rmse = SGD(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Stochastic Gradient Descent | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Multi-Layer Perceptron||\")\n",
    "rmse = MLP(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Multi-Layer Perceptron | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||XGBoost||\")\n",
    "rmse = XGB(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"XGBoost | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stacking||\")\n",
    "rmse = Stacking(x_train_raw, y_train, x_valid_raw, y_valid, x_test_raw, y_test)\n",
    "print(\"Stacking | RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5708c9c-bd85-4dac-a79c-fbdb5035f2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Government Data with Facility Information ====\n",
      "\n",
      "||Ridge Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 鄉鎮市區_萬華區, 建材_鋼骨造, 鄉鎮市區_大同區, 移轉層次項目_平台, 建物型態_店面(店鋪), 使用分區_住宅用地, 移轉層次項目_騎樓, 主要用途_見使用執照, 鄉鎮市區_北投區\n",
      "Ridge Regression | RMSE = 39711.9329989575 \n",
      "\n",
      "||Lasso Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 鄉鎮市區_萬華區, 建材_鋼骨造, 移轉層次項目_平台, 移轉層次項目_騎樓, 建物型態_店面(店鋪), 主要用途_見使用執照, 建材_鋼骨鋼筋混凝土造, 鄉鎮市區_大同區, 主要用途_見其他登記事項\n",
      "Lasso Regression | RMSE = 39696.25589837171 \n",
      "\n",
      "||KNN||\n",
      "best n_neighbors: 14\n",
      "best weights: distance\n",
      "best leaf_size: 1\n",
      "==========\n",
      "KNN | RMSE = 36024.7776388928 \n",
      "\n",
      "||Random Forest||\n",
      "best n_estimators: 280\n",
      "==========\n",
      "The 10 most important features:\n",
      "金融機構, 屋齡, 建物型態_公寓(5樓含以下無電梯), 建物移轉總面積平方公尺, 高中職, 超商, 土地移轉總面積平方公尺, 移轉層次, 大賣場, 建材_鋼筋混凝土造\n",
      "Random Forest | RMSE = 33387.083343008955\n",
      "Random Forest | OOB Score = 0.6733493161991587 \n",
      "\n",
      "||Bagging||\n",
      "best n_estimators: 200\n",
      "==========\n",
      "Bagging | RMSE = 33352.51711337207\n",
      "Bagging | OOB Score = 0.6713803755008805 \n",
      "\n",
      "||Decision Tree||\n",
      "best criterion: absolute_error\n",
      "best max_depth: 5\n",
      "best min_samples_split: 9\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 金融機構, 屋齡, 高中職, 建材_鋼筋混凝土造, 警察局, 大賣場, 移轉層次, 鄉鎮市區_萬華區, 鄉鎮市區_大安區\n",
      "Decision Tree | RMSE = 44169.09586124408 \n",
      "\n",
      "||Gradient Boosting||\n",
      "best loss: huber\n",
      "best learning_rate: 0.2\n",
      "best n_estimators: 160\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 金融機構, 屋齡, 鄉鎮市區_大安區, 超商, 大賣場, 鄉鎮市區_萬華區, 建材_鋼筋混凝土造, 消防局, 移轉層次\n",
      "Gradient Boosting | RMSE = 34834.64526128846 \n",
      "\n",
      "||Ada Boosting||\n",
      "best loss: exponential\n",
      "best learning_rate: 1.5\n",
      "best n_estimators: 30\n",
      "==========\n",
      "The 10 most important features:\n",
      "屋齡, 建物現況格局-房, 移轉層次, 金融機構, 高中職, 超商, 建物移轉總面積平方公尺, 鄉鎮市區_北投區, 鄉鎮市區_大安區, 大賣場\n",
      "Ada Boosting | RMSE = 45654.77296934344 \n",
      "\n",
      "||Support Vector Machine||\n",
      "best kernel: linear\n",
      "best C: 2.9000000000000004\n",
      "==========\n",
      "Support Vector Machine | RMSE = 48396.436312789636 \n",
      "\n",
      "||Stochastic Gradient Descent||\n",
      "best loss: squared_error\n",
      "best penalty: l1\n",
      "best alpha: 0.0001\n",
      "==========\n",
      "Stochastic Gradient Descent | RMSE = 39898.53173426752 \n",
      "\n",
      "||Multi-Layer Perceptron||\n",
      "Multi-Layer Perceptron | RMSE = 46227.38592627708 \n",
      "\n",
      "||XGBoost||\n",
      "best n_estimators: 49\n",
      "==========\n",
      "XGBoost | RMSE = 34338.993922707 \n",
      "\n",
      "||Stacking||\n",
      "Stacking | RMSE = 32934.54850065288\n"
     ]
    }
   ],
   "source": [
    "# Evaluation: Government Data with Facility Information\n",
    "print(\"==== Government Data with Facility Information ====\\n\")\n",
    "\n",
    "print(\"||Ridge Regression||\")\n",
    "rmse = Ridgereg(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Ridge Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Lasso Regression||\")\n",
    "rmse = Lassoreg(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Lasso Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||KNN||\")\n",
    "rmse = KNN(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"KNN | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Random Forest||\")\n",
    "oob, rmse = RandomForest(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Random Forest | RMSE =\", rmse)\n",
    "print(\"Random Forest | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Bagging||\")\n",
    "oob, rmse = Bagging(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Bagging | RMSE =\", rmse)\n",
    "print(\"Bagging | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Decision Tree||\")\n",
    "rmse = DecisionTree(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Decision Tree | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Gradient Boosting||\")\n",
    "rmse = GBoosting(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Gradient Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Ada Boosting||\")\n",
    "rmse = AdaBoost(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Ada Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Support Vector Machine||\")\n",
    "rmse = SVM(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Support Vector Machine | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stochastic Gradient Descent||\")\n",
    "rmse = SGD(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Stochastic Gradient Descent | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Multi-Layer Perceptron||\")\n",
    "rmse = MLP(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Multi-Layer Perceptron | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||XGBoost||\")\n",
    "rmse = XGB(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"XGBoost | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stacking||\")\n",
    "rmse = Stacking(x_train_fac, y_train, x_valid_fac, y_valid, x_test_fac, y_test)\n",
    "print(\"Stacking | RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a3fd58a-4729-409d-acfc-484deb362625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Above data with Street Scene Data ====\n",
      "\n",
      "||Ridge Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 建材_鋼骨造, 鄉鎮市區_中正區, 鄉鎮市區_松山區, 移轉層次項目_平台, 鄉鎮市區_信義區, 建物型態_店面(店鋪), 鄉鎮市區_萬華區, 建材_鋼骨鋼筋混凝土造, 使用分區_住宅用地\n",
      "Ridge Regression | RMSE = 39472.84058505757 \n",
      "\n",
      "||Lasso Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 建材_鋼骨造, 鄉鎮市區_中正區, 建材_鋼骨鋼筋混凝土造, 移轉層次項目_平台, 鄉鎮市區_松山區, 鄉鎮市區_信義區, 建物型態_店面(店鋪), 主要用途_自由職業事務所, 鄉鎮市區_萬華區\n",
      "Lasso Regression | RMSE = 39453.74146587292 \n",
      "\n",
      "||KNN||\n",
      "best n_neighbors: 11\n",
      "best weights: distance\n",
      "best leaf_size: 1\n",
      "==========\n",
      "KNN | RMSE = 39909.39473587987 \n",
      "\n",
      "||Random Forest||\n",
      "best n_estimators: 200\n",
      "==========\n",
      "The 10 most important features:\n",
      "金融機構, 屋齡, 建物型態_公寓(5樓含以下無電梯), 高中職, 建材_鋼筋混凝土造, 大賣場, 移轉層次, 超商, 鄉鎮市區_大安區, 建物移轉總面積平方公尺\n",
      "Random Forest | RMSE = 35188.12913695446\n",
      "Random Forest | OOB Score = 0.6316459521596338 \n",
      "\n",
      "||Bagging||\n",
      "best n_estimators: 280\n",
      "==========\n",
      "Bagging | RMSE = 35150.479701364224\n",
      "Bagging | OOB Score = 0.6323601847428955 \n",
      "\n",
      "||Decision Tree||\n",
      "best criterion: squared_error\n",
      "best max_depth: 5\n",
      "best min_samples_split: 3\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 金融機構, 屋齡, 建材_鋼筋混凝土造, 高中職, 大賣場, 移轉層次, 鄉鎮市區_大安區, 超商, 鄉鎮市區_萬華區\n",
      "Decision Tree | RMSE = 43474.395354682434 \n",
      "\n",
      "||Gradient Boosting||\n",
      "best loss: huber\n",
      "best learning_rate: 0.1\n",
      "best n_estimators: 120\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 金融機構, 屋齡, 超商, 鄉鎮市區_大安區, 大賣場, 鄉鎮市區_萬華區, 消防局, 建材_鋼筋混凝土造, 移轉層次\n",
      "Gradient Boosting | RMSE = 36852.57483306209 \n",
      "\n",
      "||Ada Boosting||\n",
      "best loss: exponential\n",
      "best learning_rate: 0.3\n",
      "best n_estimators: 120\n",
      "==========\n",
      "The 10 most important features:\n",
      "屋齡, 建物現況格局-房, 鄉鎮市區_大安區, 金融機構, 超商, 鄉鎮市區_北投區, 建物移轉總面積平方公尺, 移轉層次, 建物型態_公寓(5樓含以下無電梯), 高中職\n",
      "Ada Boosting | RMSE = 45418.97561402794 \n",
      "\n",
      "||Support Vector Machine||\n",
      "best kernel: linear\n",
      "best C: 2.9000000000000004\n",
      "==========\n",
      "Support Vector Machine | RMSE = 47402.98838481109 \n",
      "\n",
      "||Stochastic Gradient Descent||\n",
      "best loss: squared_error\n",
      "best penalty: l1\n",
      "best alpha: 0.1\n",
      "==========\n",
      "Stochastic Gradient Descent | RMSE = 39772.57085960841 \n",
      "\n",
      "||Multi-Layer Perceptron||\n",
      "Multi-Layer Perceptron | RMSE = 45465.64064698031 \n",
      "\n",
      "||XGBoost||\n",
      "best n_estimators: 24\n",
      "==========\n",
      "XGBoost | RMSE = 35389.21453414244 \n",
      "\n",
      "||Stacking||\n",
      "Stacking | RMSE = 34466.47921332673\n"
     ]
    }
   ],
   "source": [
    "# Evaluation: Above data with Street Scene Data\n",
    "print(\"==== Above data with Street Scene Data ====\\n\")\n",
    "\n",
    "\n",
    "print(\"||Ridge Regression||\")\n",
    "rmse = Ridgereg(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Ridge Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Lasso Regression||\")\n",
    "rmse = Lassoreg(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Lasso Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||KNN||\")\n",
    "rmse = KNN(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"KNN | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Random Forest||\")\n",
    "oob, rmse = RandomForest(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Random Forest | RMSE =\", rmse)\n",
    "print(\"Random Forest | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Bagging||\")\n",
    "oob, rmse = Bagging(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Bagging | RMSE =\", rmse)\n",
    "print(\"Bagging | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Decision Tree||\")\n",
    "rmse = DecisionTree(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Decision Tree | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Gradient Boosting||\")\n",
    "rmse = GBoosting(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Gradient Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Ada Boosting||\")\n",
    "rmse = AdaBoost(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Ada Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Support Vector Machine||\")\n",
    "rmse = SVM(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Support Vector Machine | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stochastic Gradient Descent||\")\n",
    "rmse = SGD(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Stochastic Gradient Descent | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Multi-Layer Perceptron||\")\n",
    "rmse = MLP(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Multi-Layer Perceptron | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||XGBoost||\")\n",
    "rmse = XGB(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"XGBoost | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stacking||\")\n",
    "rmse = Stacking(x_train_fac_street, y_train, x_valid_fac_street, y_valid, x_test_fac_street, y_test)\n",
    "print(\"Stacking | RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0b99449-1f0e-40ec-ae97-b5dd29f3108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Above data with Satellite data ====\n",
      "\n",
      "||Ridge Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 鄉鎮市區_中正區, 鄉鎮市區_信義區, 鄉鎮市區_松山區, 建材_鋼骨造, 建材_鋼骨鋼筋混凝土造, 移轉層次項目_平台, 建物型態_店面(店鋪), 鄉鎮市區_萬華區, 移轉層次項目_騎樓\n",
      "Ridge Regression | RMSE = 38971.92559278172 \n",
      "\n",
      "||Lasso Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 建材_鋼骨造, 建材_鋼骨鋼筋混凝土造, 鄉鎮市區_中正區, 鄉鎮市區_信義區, 鄉鎮市區_松山區, 移轉層次項目_平台, 建物型態_店面(店鋪), 移轉層次項目_騎樓, 建材_見其他登記事項\n",
      "Lasso Regression | RMSE = 38957.8721603581 \n",
      "\n",
      "||KNN||\n",
      "best n_neighbors: 10\n",
      "best weights: distance\n",
      "best leaf_size: 1\n",
      "==========\n",
      "KNN | RMSE = 35787.70928863243 \n",
      "\n",
      "||Random Forest||\n",
      "best n_estimators: 260\n",
      "==========\n",
      "The 10 most important features:\n",
      "金融機構, 屋齡, 建物型態_公寓(5樓含以下無電梯), 建材_鋼筋混凝土造, 高中職, 移轉層次, 鄉鎮市區_大安區, 大賣場, 超商, Sat4\n",
      "Random Forest | RMSE = 34160.834912322745\n",
      "Random Forest | OOB Score = 0.6559201252046813 \n",
      "\n",
      "||Bagging||\n",
      "best n_estimators: 260\n",
      "==========\n",
      "Bagging | RMSE = 34146.50780088224\n",
      "Bagging | OOB Score = 0.6559830028402012 \n",
      "\n",
      "||Decision Tree||\n",
      "best criterion: absolute_error\n",
      "best max_depth: 5\n",
      "best min_samples_split: 2\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 金融機構, 屋齡, Sat4, 高中職, 建材_鋼筋混凝土造, 鄉鎮市區_萬華區, 移轉層次, 大賣場, 鄉鎮市區_大安區\n",
      "Decision Tree | RMSE = 44519.05086221687 \n",
      "\n",
      "||Gradient Boosting||\n",
      "best loss: huber\n",
      "best learning_rate: 0.1\n",
      "best n_estimators: 140\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 金融機構, 屋齡, 超商, 鄉鎮市區_大安區, 鄉鎮市區_萬華區, 大賣場, 建材_鋼筋混凝土造, 消防局, 移轉層次\n",
      "Gradient Boosting | RMSE = 36413.972631848694 \n",
      "\n",
      "||Ada Boosting||\n",
      "best loss: square\n",
      "best learning_rate: 0.8\n",
      "best n_estimators: 130\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物現況格局-房, 屋齡, Sat14, 鄉鎮市區_北投區, 土地移轉總面積平方公尺, 移轉層次, Sat4, 超商, 鄉鎮市區_大安區, 建材_鋼筋混凝土造\n",
      "Ada Boosting | RMSE = 46179.820040420615 \n",
      "\n",
      "||Support Vector Machine||\n",
      "best kernel: linear\n",
      "best C: 2.9000000000000004\n",
      "==========\n",
      "Support Vector Machine | RMSE = 46315.407264739886 \n",
      "\n",
      "||Stochastic Gradient Descent||\n",
      "best loss: squared_error\n",
      "best penalty: l2\n",
      "best alpha: 0.001\n",
      "==========\n",
      "Stochastic Gradient Descent | RMSE = 39289.73079053727 \n",
      "\n",
      "||Multi-Layer Perceptron||\n",
      "Multi-Layer Perceptron | RMSE = 45558.9283165702 \n",
      "\n",
      "||XGBoost||\n",
      "best n_estimators: 17\n",
      "==========\n",
      "XGBoost | RMSE = 35352.62248392191 \n",
      "\n",
      "||Stacking||\n",
      "Stacking | RMSE = 33214.41430958335\n"
     ]
    }
   ],
   "source": [
    "# Evaluation: Above data with Satellite data\n",
    "print(\"==== Above data with Satellite data ====\\n\")\n",
    "\n",
    "print(\"||Ridge Regression||\")\n",
    "rmse = Ridgereg(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Ridge Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Lasso Regression||\")\n",
    "rmse = Lassoreg(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Lasso Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||KNN||\")\n",
    "rmse = KNN(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"KNN | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Random Forest||\")\n",
    "oob, rmse = RandomForest(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Random Forest | RMSE =\", rmse)\n",
    "print(\"Random Forest | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Bagging||\")\n",
    "oob, rmse = Bagging(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Bagging | RMSE =\", rmse)\n",
    "print(\"Bagging | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Decision Tree||\")\n",
    "rmse = DecisionTree(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Decision Tree | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Gradient Boosting||\")\n",
    "rmse = GBoosting(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Gradient Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Ada Boosting||\")\n",
    "rmse = AdaBoost(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Ada Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Support Vector Machine||\")\n",
    "rmse = SVM(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Support Vector Machine | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stochastic Gradient Descent||\")\n",
    "rmse = SGD(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Stochastic Gradient Descent | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Multi-Layer Perceptron||\")\n",
    "rmse = MLP(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Multi-Layer Perceptron | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||XGBoost||\")\n",
    "rmse = XGB(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"XGBoost | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stacking||\")\n",
    "rmse = Stacking(x_train_fac_satel, y_train, x_valid_fac_satel, y_valid, x_test_fac_satel, y_test)\n",
    "print(\"Stacking | RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad000945-ab33-47f0-b453-0f52260f5614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== All data included ====\n",
      "\n",
      "||Ridge Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 鄉鎮市區_中正區, 鄉鎮市區_信義區, 建材_鋼骨造, 鄉鎮市區_松山區, 建物型態_店面(店鋪), 鄉鎮市區_萬華區, 移轉層次項目_平台, 建材_鋼骨鋼筋混凝土造, 移轉層次項目_騎樓\n",
      "Ridge Regression | RMSE = 38591.414097405825 \n",
      "\n",
      "||Lasso Regression||\n",
      "best alpha: 4.900000000000004\n",
      "==========\n",
      "The 10 most important features:\n",
      "鄉鎮市區_大安區, 建材_鋼骨造, 鄉鎮市區_中正區, 建材_鋼骨鋼筋混凝土造, 鄉鎮市區_信義區, 鄉鎮市區_松山區, 移轉層次項目_平台, 建物型態_店面(店鋪), 移轉層次項目_騎樓, 建材_見其他登記事項\n",
      "Lasso Regression | RMSE = 38575.04332916942 \n",
      "\n",
      "||KNN||\n",
      "best n_neighbors: 20\n",
      "best weights: distance\n",
      "best leaf_size: 1\n",
      "==========\n",
      "KNN | RMSE = 38698.72902698795 \n",
      "\n",
      "||Random Forest||\n",
      "best n_estimators: 220\n",
      "==========\n",
      "The 10 most important features:\n",
      "金融機構, 建物型態_公寓(5樓含以下無電梯), 屋齡, 建材_鋼筋混凝土造, 高中職, 移轉層次, 鄉鎮市區_大安區, 大賣場, 超商, Sat4\n",
      "Random Forest | RMSE = 34932.13022475802\n",
      "Random Forest | OOB Score = 0.6378945086428703 \n",
      "\n",
      "||Bagging||\n",
      "best n_estimators: 240\n",
      "==========\n",
      "Bagging | RMSE = 34854.57439878327\n",
      "Bagging | OOB Score = 0.6397787527348187 \n",
      "\n",
      "||Decision Tree||\n",
      "best criterion: absolute_error\n",
      "best max_depth: 5\n",
      "best min_samples_split: 2\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 金融機構, 屋齡, Sat4, 高中職, 建材_鋼筋混凝土造, 鄉鎮市區_萬華區, 移轉層次, 大賣場, 鄉鎮市區_大安區\n",
      "Decision Tree | RMSE = 44519.05086221687 \n",
      "\n",
      "||Gradient Boosting||\n",
      "best loss: huber\n",
      "best learning_rate: 0.1\n",
      "best n_estimators: 120\n",
      "==========\n",
      "The 10 most important features:\n",
      "建物型態_公寓(5樓含以下無電梯), 金融機構, 屋齡, 超商, 鄉鎮市區_大安區, 鄉鎮市區_萬華區, 大賣場, 建材_鋼筋混凝土造, 移轉層次, 消防局\n",
      "Gradient Boosting | RMSE = 36859.268589621424 \n",
      "\n",
      "||Ada Boosting||\n",
      "best loss: square\n",
      "best learning_rate: 0.5\n",
      "best n_estimators: 140\n",
      "==========\n",
      "The 10 most important features:\n",
      "屋齡, 建物現況格局-房, 鄉鎮市區_北投區, 移轉層次, 鄉鎮市區_大安區, 建材_鋼筋混凝土造, 超商, Sat1, 建物移轉總面積平方公尺, Sat4\n",
      "Ada Boosting | RMSE = 46453.7781841717 \n",
      "\n",
      "||Support Vector Machine||\n",
      "best kernel: linear\n",
      "best C: 2.9000000000000004\n",
      "==========\n",
      "Support Vector Machine | RMSE = 45615.88442559486 \n",
      "\n",
      "||Stochastic Gradient Descent||\n",
      "best loss: squared_error\n",
      "best penalty: l1\n",
      "best alpha: 1e-06\n",
      "==========\n",
      "Stochastic Gradient Descent | RMSE = 38879.958983623896 \n",
      "\n",
      "||Multi-Layer Perceptron||\n",
      "Multi-Layer Perceptron | RMSE = 45281.533324427 \n",
      "\n",
      "||XGBoost||\n",
      "best n_estimators: 29\n",
      "==========\n",
      "XGBoost | RMSE = 35214.24070829195 \n",
      "\n",
      "||Stacking||\n",
      "Stacking | RMSE = 33978.533612715284\n"
     ]
    }
   ],
   "source": [
    "# Evaluation: All data included\n",
    "print(\"==== All data included ====\\n\")\n",
    "\n",
    "print(\"||Ridge Regression||\")\n",
    "rmse = Ridgereg(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Ridge Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Lasso Regression||\")\n",
    "rmse = Lassoreg(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Lasso Regression | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||KNN||\")\n",
    "rmse = KNN(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"KNN | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Random Forest||\")\n",
    "oob, rmse = RandomForest(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Random Forest | RMSE =\", rmse)\n",
    "print(\"Random Forest | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Bagging||\")\n",
    "oob, rmse = Bagging(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Bagging | RMSE =\", rmse)\n",
    "print(\"Bagging | OOB Score =\", oob, \"\\n\")\n",
    "\n",
    "print(\"||Decision Tree||\")\n",
    "rmse = DecisionTree(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Decision Tree | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Gradient Boosting||\")\n",
    "rmse = GBoosting(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Gradient Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Ada Boosting||\")\n",
    "rmse = AdaBoost(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Ada Boosting | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Support Vector Machine||\")\n",
    "rmse = SVM(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Support Vector Machine | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stochastic Gradient Descent||\")\n",
    "rmse = SGD(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Stochastic Gradient Descent | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Multi-Layer Perceptron||\")\n",
    "rmse = MLP(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Multi-Layer Perceptron | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||XGBoost||\")\n",
    "rmse = XGB(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"XGBoost | RMSE =\", rmse, \"\\n\")\n",
    "\n",
    "print(\"||Stacking||\")\n",
    "rmse = Stacking(x_train_full, y_train, x_valid_full, y_valid, x_test_full, y_test)\n",
    "print(\"Stacking | RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba747d8-ba6f-4007-9aa2-1e8491b95745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
